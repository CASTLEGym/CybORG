{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c0c32c-7c80-43af-a8fa-2a0ee2177411",
   "metadata": {},
   "source": [
    "## Scenario Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd37fa-3023-47cb-8782-1b383ebf086c",
   "metadata": {},
   "source": [
    "### CAGE Challenge 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9cad4-4372-4c76-83b6-6054f13a8f73",
   "metadata": {},
   "source": [
    "Your firm has been contracted by Florin to trial your new autonomous defence agents. Florin have given your agent authority to defend the computer network at one of their manufacturing plants. The network, shown in Figure 1, contains a user network for staff, an enterprise network, and an operational network which contains the key manufacturing and logistics servers. The defence agent receives an alert feed from Florin’s existing monitoring systems. It can run detailed analyses on hosts, then remove malicious software if found. If an attacker is too well established on a host to be removed, the host can be restored from a clean backup. Finally, the defence agent can deceive attackers by creating decoy services.\n",
    "\n",
    "The network owner has undertaken an evaluation of the factory systems and contracted your firm to defend these systems according to the following criteria:\n",
    "\n",
    "Maintain the critical operational server to ensure information about the new weapon system is not revealed to Guilder and the production and delivery of the new weapon system remains on schedule.\n",
    "Where possible, maintain enterprise servers to ensure day-to-day operations of the manufacturing plant are not disrupted or revealed.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315e4f0-8965-4b44-8eeb-bb3eb8c9f33d",
   "metadata": {},
   "source": [
    "Subnet 1 consists of user hosts that are not critical. \\\n",
    "Subnet 2 consists of enterprise servers designed to support the user activities on Subnet 1. \\\n",
    "Subnet 3 contains the critical operational server and three user hosts.\n",
    "\n",
    "<img src=\"https://github.com/cage-challenge/cage-challenge-2/raw/main/images/figure1.png\">\n",
    "\n",
    "The effect of each action on the state of a targeted host is summarized with the diagram.\n",
    "\n",
    "<img src=\"https://github.com/cage-challenge/cage-challenge-2/raw/main/images/figure2.png\" caption=\"State Diagram\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb903b-25eb-4fae-af5d-91e0bef2ccda",
   "metadata": {},
   "source": [
    "### Appendix - Action Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c259e9a-a918-45ca-bea1-cd968b023dcc",
   "metadata": {},
   "source": [
    "Blue Action Sets\n",
    "    \n",
    "| Action     | Purpose                                                                                                                                                                                                                                                 | Parameters                                                                    | Output                                 |\n",
    "|:-----------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------|:---------------------------------------|\n",
    "| Monitor | Collection of information about flagged malicious activity on the system\\. Corresponds to action ID 1: Scan in the OpenC2 specification[^3]\\.                                                                                                           | None *\\(Note: This action occurs automatically if another action is chosen\\)* | Network connections and associated processes that are identified as malicious\\. |\n",
    "| Analyse | Collection of further information on a specific host to enable blue to better identify if red is present on the system\\. Corresponds to action ID 30: Investigate in the OpenC2 specification\\.                                                         | Hostname                                                                      | Information on files associated with recent alerts including signature and entropy\\.  |\n",
    "| DecoyApache, DecoyFemitter, DecoyHarakaSMPT, DecoySmss, DecoySSHD, DecoySvchost, DecoyTomcat | Setup of a decoy service (as specified by the action name) on a specified host\\. Green agents do not access these services, so any access is a clear example of red activity\\.                                                                                                            | Hostname                                                                | An alert if the red agent accesses the new service\\. |\n",
    "| Remove | Attempting to remove red from a host by destroying malicious processes, files and services\\. This action attempts to stop all processes identified as malicious by the monitor action\\. Corresponds to action ID 10: Stop in the OpenC2 specification\\. | Hostname                                                                      | Success/Failure |\n",
    "| Restore | Restoring a system to a known good state\\. This has significant consequences for system availability\\. This action punishes Blue by \\-1\\. Corresponds to action ID 23: Restore in the OpenC2 specification\\.                                            | Hostname                                                                      | Success/Failure  |\n",
    "\n",
    "\n",
    "Red Action Sets\n",
    "    \n",
    "| Action     | Purpose                                                                                                                                                    | Parameters       | Output                                 |\n",
    "|:-----------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------|:---------------------------------------|\n",
    "| Discover Remote Systems | ATT&CK[^4] Technique T1018 Remote System Discovery\\. Discovers new hosts/IP addresses in the network through active scanning using tools such as ping\\.    | Subnet           | IP addresses in the chosen subnet from hosts that respond to ping |\n",
    "| Discover Network Services | ATT&CK Technique T1046 Network Service Scanning. Discovers responsive services on a selected host by initiating a connection with that host\\.              | Subnet           | Ports and service information |\n",
    "| Exploit Network Services | ATT&CK Technique T1210 Exploitation of Remote Services\\. This action attempts to exploit a specified service on a remote system\\.                          | IP Address, Port | Success/Failure <br /> Initial recon of host if successful. |\n",
    "| Escalate | ATT&CK Tactic TA0004 Privilege Escalation\\. This action escalates the agent’s privilege on the host\\.                                                      | Hostname         | Success/Failure <p> Internal information now available due to increased access to the host |\n",
    "| Impact | ATT&CK Technique T1489 Service Stop\\. This action disrupts the performance of the network and fulfils red’s objective of denying the operational service\\. | Hostname         | Success/Failure  |\n",
    "\n",
    "[^3]: Open Command and Control \\(OpenC2\\), [https://openc2\\.org/](https://openc2\\.org/)\n",
    "\n",
    "[^4]: MITRE ATT&CK, [https://attack\\.mitre\\.org/](https://attack\\.mitre\\.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59ac41-7553-4563-b97d-ca4708e6347d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2279eef-ac10-44b8-a4ba-817f95f739f5",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdda0f8-7dcc-469a-9a90-785adf78935f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- Rules-based agents\n",
    "- Deep Reinforcement Learning agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76050b-d358-4bba-932a-a7001f160ed8",
   "metadata": {},
   "source": [
    "### Rule-based agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d8a4b-0918-4b6a-8b78-b73f4b69874c",
   "metadata": {},
   "source": [
    "- Blue\n",
    "    - RandomAgent: Takes a random action or a test action based on the epsilon value\n",
    "    - BlueReactRemoveAgent: Adds suspicious hosts to the host list if the monitor finds something and then it will remove the program(session)\n",
    "    - BlueReactRestoreAgent: Similar steps but restore the host from a cleaned backup.\n",
    "- Red\n",
    "    - RedMeanderAgent: Explores the network one subnet at a time, seeking to gain privileged access to all hosts in a subnet before moving on to the next one, eventually arriving at the Operational Server.\n",
    "    - B_lineAgent: Attempts to move straight to the Operational Server using prior knowledge of the network layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d616717c-5de7-4da4-8db4-08606816a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71fd1ed-253a-4d5d-a0aa-773d9b5caaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import inspect\n",
    "import time\n",
    "import os\n",
    "from statistics import mean, stdev\n",
    "import random\n",
    "import collections\n",
    "from pprint import pprint\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx import connected_components\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "from CybORG import CybORG, CYBORG_VERSION\n",
    "\n",
    "from CybORG.Agents import B_lineAgent, BlueReactRestoreAgent, BlueReactRemoveAgent, \\\n",
    "     RedMeanderAgent, SleepAgent\n",
    "from CybORG.Agents.MainAgent import MainAgent\n",
    "\n",
    "from CybORG.Agents.Wrappers.ChallengeWrapper import ChallengeWrapper\n",
    "# from CybORG.Agents.Wrappers.ChallengeWrapper2 import ChallengeWrapper2\n",
    "from CybORG.Agents.Wrappers import EnumActionWrapper\n",
    "from CybORG.Agents.Wrappers.FixedFlatWrapper import FixedFlatWrapper\n",
    "from CybORG.Agents.Wrappers.IntListToAction import IntListToActionWrapper\n",
    "from CybORG.Agents.Wrappers.OpenAIGymWrapper import OpenAIGymWrapper\n",
    "# from CybORG.Simulator.Scenarios.FileReaderScenarioGenerator import FileReaderScenarioGenerator\n",
    "\n",
    "from CybORG.Tutorial.Visualizers import NetworkVisualizer\n",
    "from CybORG.Tutorial.GameStateManager import GameStateManager\n",
    "from CybORG.Tutorial.Mininet import MininetAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051c4b0b-b7fd-4abf-9c58-67d9af6151e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagram.pyhps://diagrams.mingrammer.com/docs/getting-started/examples\n",
    "# from diagrams import Diagram\n",
    "# from diagrams.aws.compute import EC2\n",
    "# from diagrams.aws.database import RDS\n",
    "# from diagrams.aws.network import ELB\n",
    "\n",
    "# with Diagram(\"Web Service\", show=False):\n",
    "#     ELB(\"lb\") >> EC2(\"web\") >> RDS(\"userdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f0c8f-fa74-48e3-94cd-fcdedc2730c7",
   "metadata": {},
   "source": [
    "## A Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbcbf36-bbb4-49cf-adad-ff746c200a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CybORG.Tutorial.CybORG_As_A_Service import InteractiveCybORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f31668-3821-4966-b0bb-bf79ad8adbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test InteractiveCybORG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191618d5-f099-4ff4-9918-733a81695225",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "- input \n",
    "    - Observation from Red and Blue\n",
    "    - Action for Blue / Red?\n",
    "    - link_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b8eee-83db-4333-b675-49504122a4fb",
   "metadata": {},
   "source": [
    "Mouse over event oberservations \n",
    "Different Shape\n",
    "Different State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756b9c54-ff4d-4ced-b2ae-b5717c5397b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPS = 1\n",
    "agent_name = 'Blue'\n",
    "random.seed(0)\n",
    "cyborg_version = CYBORG_VERSION\n",
    "scenario = 'Scenario2'\n",
    "\n",
    "def wrap(env):\n",
    "    # return ChallengeWrapper2(env=env, agent_name='Blue')\n",
    "    return ChallengeWrapper(env=env, agent_name='Blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1858c2d7-89ca-44c4-b54b-f7a0c7cd7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cyborg_version = CYBORG_VERSION\n",
    "    scenario = 'Scenario2'\n",
    "    # commit_hash = get_git_revision_hash()\n",
    "    commit_hash = \"Not using git\"\n",
    "    # ask for a name\n",
    "    name = \"John Hannay\"\n",
    "    # ask for a team\n",
    "    team = \"CardiffUni\"\n",
    "    # ask for a name for the agent\n",
    "    name_of_agent = \"PPO + Greedy decoys\"\n",
    "\n",
    "    lines = inspect.getsource(wrap)\n",
    "    wrap_line = lines.split('\\n')[1].split('return ')[1]\n",
    "\n",
    "    # Change this line to load your agent\n",
    "    agent = MainAgent()\n",
    "    \n",
    "    print(f'Using agent {agent.__class__.__name__}, if this is incorrect please update the code to load in your agent')\n",
    "\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    # path = path[:-7] + f'/Simulator/Scenarios/scenario_files/Scenario2.yaml'\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario2.yaml'\n",
    "\n",
    "    print(f'using CybORG v{cyborg_version}, {scenario}\\n')\n",
    "    \n",
    "    # game manager initialization\n",
    "    game_state_manager = GameStateManager()\n",
    "    mininet_adapter = MininetAdapter()\n",
    "\n",
    "    for num_steps in [3]:\n",
    "        for red_agent in [B_lineAgent]:\n",
    "            # red_agent = red_agent()\n",
    "            cyborg = CybORG(path, 'sim', agents={'Red': red_agent})\n",
    "            wrapped_cyborg = wrap(cyborg)\n",
    "\n",
    "            observation = wrapped_cyborg.reset()\n",
    "            # observation = cyborg.reset().observation\n",
    "\n",
    "            # set up game_state_manager\n",
    "            # game_state_manager.set_environment(cyborg=cyborg,\n",
    "            #                                    red_agent=red_agent,\n",
    "            #                                    blue_agent=agent,\n",
    "            #                                    num_steps=num_steps)\n",
    "\n",
    "            # Reset mininet adapter \n",
    "            mininet_adapter.set_environment(cyborg=cyborg)\n",
    "            mininet_adapter.reset()\n",
    "            \n",
    "            action_space = wrapped_cyborg.get_action_space(agent_name)\n",
    "            # action_space = cyborg.get_action_space(agent_name)\n",
    "            total_reward = []\n",
    "            actions = []\n",
    "            for i in range(MAX_EPS):\n",
    "                r = []\n",
    "                a = []\n",
    "                \n",
    "                # cyborg.env.env.tracker.render()\n",
    "                for j in range(num_steps):\n",
    "                    action = agent.get_action(observation, action_space)\n",
    "                    observation, rew, done, info = wrapped_cyborg.step(action)\n",
    "                    # result = cyborg.step(agent_name, action)\n",
    "                    r.append(rew)\n",
    "                    # r.append(result.reward)\n",
    "                    a.append((str(cyborg.get_last_action('Blue')), str(cyborg.get_last_action('Red'))))\n",
    "                    pprint(a)\n",
    "                    # create state for this step\n",
    "                    # state_snapshot = game_state_manager.create_state_snapshot()\n",
    "                    # game manager store state\n",
    "                    # game_state_manager.store_state(state_snapshot, i, j)\n",
    "                    mininet_adapter.perform_emulation()\n",
    "\n",
    "                # game manager reset\n",
    "                agent.end_episode()\n",
    "                total_reward.append(sum(r))\n",
    "                actions.append(a)\n",
    "                # observation = cyborg.reset().observation\n",
    "                observation = wrapped_cyborg.reset()\n",
    "                # game_state_manager.reset()\n",
    "                mininet_adapter.reset()\n",
    "        \n",
    "        mininet_adapter.clean()\n",
    "    return game_state_manager.get_game_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a1fb2e-003e-4877-8ad8-db687fbb26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using agent MainAgent, if this is incorrect please update the code to load in your agent\n",
      "using CybORG v2.1, Scenario2\n",
      "\n",
      "Cleaned up the topology successfully\n",
      "{'Defender': IPv4Address('10.0.120.156'),\n",
      " 'Enterprise0': IPv4Address('10.0.120.152'),\n",
      " 'Enterprise1': IPv4Address('10.0.120.158'),\n",
      " 'Enterprise2': IPv4Address('10.0.120.155'),\n",
      " 'Op_Host0': IPv4Address('10.0.110.38'),\n",
      " 'Op_Host1': IPv4Address('10.0.110.42'),\n",
      " 'Op_Host2': IPv4Address('10.0.110.46'),\n",
      " 'Op_Server0': IPv4Address('10.0.110.34'),\n",
      " 'User0': IPv4Address('10.0.214.186'),\n",
      " 'User1': IPv4Address('10.0.214.187'),\n",
      " 'User2': IPv4Address('10.0.214.182'),\n",
      " 'User3': IPv4Address('10.0.214.180'),\n",
      " 'User4': IPv4Address('10.0.214.189')}\n",
      "An error occurred while creating the YAML file:\n",
      "'Enterprise_router'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/justinyeh1995/CASTLEGym/CybORG-v2/CybORG/CybORG/Tutorial/Mininet/Adapter.py\", line 93, in _create_yaml\n",
      "    self.topology_data['topo']['lans'] = get_lans_info(self.cyborg, self.cyborg_to_mininet_name_map)\n",
      "  File \"/home/ubuntu/justinyeh1995/CASTLEGym/CybORG/CybORG/Tutorial/Mininet/utils/util.py\", line 34, in get_lans_info\n",
      "    router_ip = str(cyborg.get_ip_map()[f'{lan_name}_router'])\n",
      "KeyError: 'Enterprise_router'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininet Topology Created Successfully:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'10.0.120.152'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%capture\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m game_state_pretained \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# observation = cyborg.reset().observation\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# set up game_state_manager\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Reset mininet adapter \u001b[39;00m\n\u001b[1;32m     47\u001b[0m mininet_adapter\u001b[38;5;241m.\u001b[39mset_environment(cyborg\u001b[38;5;241m=\u001b[39mcyborg)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mmininet_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m action_space \u001b[38;5;241m=\u001b[39m wrapped_cyborg\u001b[38;5;241m.\u001b[39mget_action_space(agent_name)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# action_space = cyborg.get_action_space(agent_name)\u001b[39;00m\n",
      "File \u001b[0;32m~/justinyeh1995/CASTLEGym/CybORG-v2/CybORG/CybORG/Tutorial/Mininet/Adapter.py:330\u001b[0m, in \u001b[0;36mMininetAdapter.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_mapping()\n\u001b[1;32m    329\u001b[0m expect_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_mininet_topo()\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpect_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/justinyeh1995/CASTLEGym/CybORG-v2/CybORG/CybORG/Tutorial/Mininet/Adapter.py:152\u001b[0m, in \u001b[0;36mMininetAdapter.update_mapping\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmininet_host_to_cyborg_ip_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_mininet_host_to_cyborg_ip_map(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopology_data) \n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_host_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_cyborg_ip_to_mininet_host_map(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopology_data)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_to_mininet_host_map \u001b[38;5;241m=\u001b[39m { \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map[cyborg_ip]:\n\u001b[1;32m    153\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_host_map[cyborg_ip] \u001b[38;5;28;01mfor\u001b[39;00m cyborg_ip \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map}\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmininet_to_cyborg_host_map \u001b[38;5;241m=\u001b[39m { \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_host_map[cyborg_ip]:\n\u001b[1;32m    156\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map[cyborg_ip] \u001b[38;5;28;01mfor\u001b[39;00m cyborg_ip \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map}\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_ip_map \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_host_to_ip_map[cyborg_h]:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmininet_host_to_ip_map[mininet_h] \n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cyborg_h, mininet_h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_to_mininet_host_map\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/justinyeh1995/CASTLEGym/CybORG-v2/CybORG/CybORG/Tutorial/Mininet/Adapter.py:153\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmininet_host_to_cyborg_ip_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_mininet_host_to_cyborg_ip_map(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopology_data) \n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_host_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_cyborg_ip_to_mininet_host_map(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopology_data)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_to_mininet_host_map \u001b[38;5;241m=\u001b[39m { \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map[cyborg_ip]:\n\u001b[0;32m--> 153\u001b[0m                                    \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcyborg_ip_to_mininet_host_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcyborg_ip\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cyborg_ip \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map}\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmininet_to_cyborg_host_map \u001b[38;5;241m=\u001b[39m { \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_host_map[cyborg_ip]:\n\u001b[1;32m    156\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map[cyborg_ip] \u001b[38;5;28;01mfor\u001b[39;00m cyborg_ip \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_host_map}\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_ip_to_mininet_ip_map \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_host_to_ip_map[cyborg_h]:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmininet_host_to_ip_map[mininet_h] \n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cyborg_h, mininet_h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcyborg_to_mininet_host_map\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mKeyError\u001b[0m: '10.0.120.152'"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "game_state_pretained = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06aea9-f7c9-4168-b195-f2d35e76a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = NetworkVisualizer(game_state_pretained)\n",
    "# nv.set_game_state(game_state_pretained)\n",
    "nv.plot(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cd58b-365d-4019-bbad-d9936d0d843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_simple_agent():\n",
    "    cyborg_version = CYBORG_VERSION\n",
    "    scenario = 'Scenario2'\n",
    "    # commit_hash = get_git_revision_hash()\n",
    "    commit_hash = \"Not using git\"\n",
    "    # ask for a name\n",
    "    name = \"John Hannay\"\n",
    "    # ask for a team\n",
    "    team = \"CardiffUni\"\n",
    "    # ask for a name for the agent\n",
    "    name_of_agent = \"PPO + Greedy decoys\"\n",
    "\n",
    "    lines = inspect.getsource(wrap)\n",
    "    wrap_line = lines.split('\\n')[1].split('return ')[1]\n",
    "\n",
    "    # Change this line to load your agent\n",
    "    agent = BlueReactRemoveAgent()\n",
    "    \n",
    "    print(f'Using agent {agent.__class__.__name__}, if this is incorrect please update the code to load in your agent')\n",
    "\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    # path = path[:-7] + f'/Simulator/Scenarios/scenario_files/Scenario2.yaml'\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario2.yaml'\n",
    "\n",
    "    # sg = FileReaderScenarioGenerator(path)\n",
    "\n",
    "    print(f'using CybORG v{cyborg_version}, {scenario}\\n')\n",
    "    \n",
    "    # game manager initialization\n",
    "    game_state_manager = GameStateManager()\n",
    "    # mininet adapter initialization\n",
    "    mininet_adapter = MininetAdapter()\n",
    "\n",
    "    \n",
    "    for num_steps in [5]:\n",
    "        for red_agent in [B_lineAgent]:\n",
    "            red_agent = red_agent()\n",
    "            cyborg = CybORG(path, 'sim', agents={'Red': red_agent})\n",
    "\n",
    "            observation = cyborg.reset()\n",
    "            # print('observation is:',observation)\n",
    "            \n",
    "            # Rest set up game_state_manager\n",
    "            game_state_manager.set_environment(cyborg=cyborg,\n",
    "                                               red_agent=red_agent,\n",
    "                                               blue_agent=agent,\n",
    "                                               num_steps=num_steps)\n",
    "            game_state_manager.reset()\n",
    "\n",
    "\n",
    "            # Reset mininet adapter \n",
    "            mininet_adapter.set_environment(cyborg=cyborg)\n",
    "            mininet_adapter.reset()\n",
    "            \n",
    "            \n",
    "            action_space = cyborg.get_action_space(agent_name)\n",
    "\n",
    "            total_reward = []\n",
    "            actions = []\n",
    "            for i in range(MAX_EPS):\n",
    "                r = []\n",
    "                a = []\n",
    "                \n",
    "                # cyborg.env.env.tracker.render()\n",
    "                for j in range(num_steps):\n",
    "                    blue_action_space = cyborg.get_action_space('Blue')\n",
    "                    blue_obs = cyborg.get_observation('Blue') # get the newest observation\n",
    "                    blue_action = agent.get_action(blue_obs, blue_action_space)\n",
    "                    # pprint(blue_action)\n",
    "                        \n",
    "                    result = cyborg.step('Blue', blue_action, skip_valid_action_check=False)\n",
    "                    \n",
    "                    # create state for this step\n",
    "                    state_snapshot = game_state_manager.create_state_snapshot()\n",
    "                    # game manager store state\n",
    "                    game_state_manager.store_state(state_snapshot, i, j)\n",
    "\n",
    "                    # The adapter should pass the action as a param\n",
    "                    mininet_adapter.perform_emulation()\n",
    "                    # pprint(mininet_adapter)\n",
    "\n",
    "                    \n",
    "                # game manager reset\n",
    "                agent.end_episode()\n",
    "                total_reward.append(sum(r))\n",
    "                actions.append(a)\n",
    "                # observation = cyborg.reset().observation\n",
    "                observation = cyborg.reset()\n",
    "                # game state manager reset\n",
    "                game_state_manager.reset()\n",
    "                # mininet adapter reset\n",
    "                mininet_adapter.reset()\n",
    "        \n",
    "        mininet_adapter.clean()\n",
    "\n",
    "    return game_state_manager.get_game_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccfc85e0-e11b-43a1-a438-f18a5b996b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# game_state_simple = main_simple_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76b89612-3582-4389-8c99-f5f1c51435d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_state_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f47eaeb-1c54-47e6-926e-377ad1029880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nv = NetworkVisualizer(game_state_simple)\n",
    "#nv.plot(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ff7eb-e70a-44af-9d0f-bbfdedd09b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_color(node, discovered_subnets=None, discovered_systems=None, exploited_hosts=None, escalated_hosts=None):\n",
    "    color = \"green\"\n",
    "    \n",
    "    if 'router' in node:\n",
    "        if node in discovered_subnets:\n",
    "            color = 'rosybrown'\n",
    "    \n",
    "    if node in discovered_systems:\n",
    "        color = \"lightgreen\"\n",
    "    \n",
    "    if node in escalated_hosts:\n",
    "        color = \"red\"\n",
    "        \n",
    "    elif node in exploited_hosts:\n",
    "        color = \"orange\"\n",
    "    \n",
    "    return color\n",
    "\n",
    "def get_node_border(node, target_host=None, reset_host=None):\n",
    "    if node in target_host:\n",
    "        border = dict(width=2, color='#99004C')\n",
    "    elif node in reset_host:\n",
    "        border = dict(width=2, color='blue')\n",
    "    else:\n",
    "        border = dict(width=0, color='white')\n",
    "    return border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d583a721-9f6a-446e-8e9e-c9c421aa71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation\n",
    "\n",
    "# router blink\n",
    "# surrond any change icon with dashlines(happnening this steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f86f44-fc6e-4eaf-a351-575dfbb5db79",
   "metadata": {},
   "source": [
    "### Example 1: Blue Remove Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184e0f0-33fc-4a9e-a8fd-1b957117e2e7",
   "metadata": {},
   "source": [
    "1. Plot action by action, instead of step by step\n",
    "2. Unify default color\n",
    "3. discover remote systems: light pink -> pink (gradually turns to red)\n",
    "4. black border for the latest action\n",
    "5. When hovering over the node, show running processes, the operating systems, images used\n",
    "6. configuration should be defined at the top / in __init__\n",
    "\n",
    "7. Try scaling up the scenarios: 10,000 nodes\n",
    "\n",
    "8. html panel / information panel / controller of the game which does animation (live/historical)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff731f79-65bf-4ea6-b464-f90992f47ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# agent = BlueReactRemoveAgent()\n",
    "# agent_game_states = run_episode_cc2(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fab56e-92aa-4f14-aa03-161d9997a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_plot(agent_game_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c01f33-0fc5-41d4-a964-5d4974a77c14",
   "metadata": {},
   "source": [
    "### Example 2: Blue Restore Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b23b838-6c6c-4811-a167-214938b6dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# agent = BlueReactRestoreAgent()\n",
    "# agent_game_states = run_episode_cc2(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8badcce4-23f0-4146-a08d-6ccc55727a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_plot(agent_game_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64994d19-3928-4976-a9df-040193017dbb",
   "metadata": {},
   "source": [
    "### Example 3: Blue Pre-trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dfad3fd-18bd-44aa-9154-013497d892e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# agent_game_states = run_pretrained_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa9f6a0-8800-46d1-9f57-9d9e23a7126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_plot(agent_game_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52cf3c1e-a048-4cdf-a3ef-dd7a63e911fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dash import Dash, dcc, html, Input, Output\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# app = Dash(__name__)\n",
    "\n",
    "\n",
    "# app.layout = html.Div([\n",
    "#     html.H4('Live data control'),\n",
    "#     dcc.Graph(id=\"graph\"),\n",
    "#     html.P(\"Change the position of the right-most data point:\"),\n",
    "#     html.Button(\"Move Up\", n_clicks=0, \n",
    "#                 id='btn-up'),\n",
    "#     html.Button(\"Move Down\", n_clicks=0,\n",
    "#                 id='btn-down'),\n",
    "# ])\n",
    "\n",
    "# @app.callback(\n",
    "#     Output(\"graph\", \"figure\"), \n",
    "#     Input(\"btn-up\", \"n_clicks\"),\n",
    "#     Input(\"btn-down\", \"n_clicks\"))\n",
    "# def make_shape_taller(n_up, n_down):\n",
    "#     n = n_up-n_down\n",
    "#     fig = go.Figure(go.Scatter(\n",
    "#         x=[1, 0, 2, 1], y=[2, 0, n, 2], # replace with your own data source\n",
    "#         fill=\"toself\"\n",
    "#     ))\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a75c5974-d4df-4603-bcbb-da971deeb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def render_game_with_matplotlib(game_states):\n",
    "#     node_shapes = {\n",
    "#         'host': 'o',    # Circle\n",
    "#         'router': '^',  # Triangle\n",
    "#         'server': 's'   # Square\n",
    "#     }\n",
    "#     for i, state in game_states.items():\n",
    "#         link_diagram = state['link_diagram']\n",
    "#         compromised_hosts = state['compromised_hosts']\n",
    "#         node_colors = state['node_colors']\n",
    "#         agent_actions = state['agent_actions']\n",
    "#         ip_map = state['ip_map']\n",
    "#         host_map = state['host_map']\n",
    "        \n",
    "#         pos = nx.spring_layout(link_diagram, seed=3113794652)  # positions for all nodes\n",
    "#         for node in link_diagram.nodes:\n",
    "#             type = \"\"\n",
    "#             if 'Server' in node:\n",
    "#                 type = 'server'\n",
    "#             elif 'router' in node:\n",
    "#                 type = 'router'\n",
    "#             else:\n",
    "#                 type = 'host'\n",
    "                \n",
    "#             if node in compromised_hosts:\n",
    "#                 nx.set_node_attributes(link_diagram, {node:{'compromised':True, 'name':node, 'type':node_shapes[type]}})\n",
    "#             else:\n",
    "#                 nx.set_node_attributes(link_diagram, {node:{'compromised':False, 'name':node, 'type':node_shapes[type]}})\n",
    "            \n",
    "            \n",
    "#         shapes = nx.get_node_attributes(link_diagram, 'type')\n",
    "        \n",
    "        \n",
    "#         nx.draw_networkx(link_diagram, pos, node_color=node_colors, with_labels=True, font_weight='bold', font_size=6)\n",
    "\n",
    "#         # Increase this value to add more space between rows\n",
    "#         vertical_padding = 0.1\n",
    "\n",
    "#         # Display Agent Action Information\n",
    "#         for idx, (agt, action_info) in enumerate(agent_actions.items()):\n",
    "#             plt.text(1.05, 1 - vertical_padding * idx, f\"{agt}: {action_info['action']} - {action_info['success']}\",\n",
    "#                      transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5))\n",
    "\n",
    "#         ip_map_start_pos = 1 - len(agent_actions) * vertical_padding - 0.1\n",
    "\n",
    "#         # Display IP Address Mapping to the right of the plot\n",
    "#         for idx, (ip, host) in enumerate(ip_map.items()):\n",
    "#             plt.text(1.05, ip_map_start_pos - idx * vertical_padding, f\"{ip}: {host}\",\n",
    "#                      transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.5))\n",
    "        \n",
    "#         plt.title(f'Step {i+1}: Network State')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fdf8a72-7224-4152-aac3-20ec4c7931ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# render_game_with_matplotlib(game_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeacfa8-8d32-4eb1-9e4a-100b3ecd5024",
   "metadata": {},
   "source": [
    "## Play trained Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc63efa-a205-49c4-8d70-cf894303852c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64abd5c-384c-4cc3-a42b-e886d31267a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q-Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ae0a656-b198-4fc4-b07f-156c75d4a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_example_q_learning(scenario):\n",
    "    agent_name = 'Red'\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-7] + f'/Simulator/Scenarios/scenario_files/{scenario}.yaml'\n",
    "    sg = FileReaderScenarioGenerator(path)\n",
    "    cyborg = CybORG(scenario_generator=sg)\n",
    "    cyborg = OpenAIGymWrapper(agent_name=agent_name,\n",
    "                              env=FixedFlatWrapper(cyborg))\n",
    "\n",
    "    observation = cyborg.reset()\n",
    "    action_space = cyborg.action_space\n",
    "    print(f\"Observation size {len(observation)}, Action Size {action_space}\")\n",
    "    action_count = 0\n",
    "    agent = RandomAgent()\n",
    "    print(agent)\n",
    "    agent.set_initial_values(action_space, observation)\n",
    "    for i in range(MAX_EPS):  # laying multiple games\n",
    "        print(f\"\\rTraining Game: {i}\\n\", end='', flush=True)\n",
    "        reward = 0\n",
    "        for j in range(MAX_STEPS_PER_GAME):  # step in 1 game\n",
    "            action = agent.get_action(observation, action_space)\n",
    "            next_observation, r, done, info = cyborg.step(action)\n",
    "\n",
    "            action_space = cyborg.action_space\n",
    "            reward += r\n",
    "\n",
    "            agent.train(observation)  # training the agent\n",
    "            observation = next_observation\n",
    "            if done or j == MAX_STEPS_PER_GAME - 1:\n",
    "                print(f\"Training reward: {reward}\")\n",
    "                break\n",
    "        agent.end_episode()\n",
    "        observation = cyborg.reset()\n",
    "        action_space = cyborg.action_space\n",
    "        agent.set_initial_values(action_space, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be94f2-9602-4fc2-9d98-21d248f03fa7",
   "metadata": {},
   "source": [
    "### Deep RL Algorithms Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1673e-a419-4801-8df5-b573579f0cc1",
   "metadata": {},
   "source": [
    "- PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f06ec47-6dc2-4ae2-8ff1-8d2fa2370413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U \"ray[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cd8668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import numpy as np\n",
    "# from CybORG import CybORG\n",
    "# from CybORG.Agents import B_lineAgent, GreenAgent\n",
    "# from CybORG.Agents.Wrappers import ChallengeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3717b9e8-e4f2-4061-80d8-f71351f0cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray import tune\n",
    "\n",
    "# tune.run(\n",
    "#     \"PPO\",\n",
    "#     config={\n",
    "#         \"env\": \"YourEnvName\",\n",
    "#         \"num_gpus\": 0,\n",
    "#         \"other_config_options\": \"...\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "818c435d-09a8-4b93-afb9-febbb616a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "# config = (  # 1. Configure the algorithm,\n",
    "#     PPOConfig()\n",
    "#     .environment(\"Taxi-v3\")\n",
    "#     .rollouts(num_rollout_workers=2)\n",
    "#     .framework(\"torch\")\n",
    "#     .training(model={\"fcnet_hiddens\": [64, 64]})\n",
    "#     .evaluation(evaluation_num_workers=1)\n",
    "# )\n",
    "\n",
    "# algo = config.build()  # 2. build the algorithm,\n",
    "\n",
    "# for _ in range(5):\n",
    "#     print(algo.train())  # 3. train it,\n",
    "\n",
    "# algo.evaluate()  # 4. and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3befce8c-e066-4eb9-83d8-e8092c399699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.rllib.algorithms import ppo\n",
    "# from ray.rllib.env import ParallelPettingZooEnv\n",
    "# from ray.tune import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe186b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CybORG.Agents.Wrappers.PettingZooParallelWrapper import PettingZooParallelWrapper\n",
    "# from CybORG.Simulator.Scenarios import FileReaderScenarioGenerator, DroneSwarmScenarioGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab4d9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLLibWrapper(ChallengeWrapper):\n",
    "    def init(self, agent_name, env, reward_threshold=None, max_steps=None):\n",
    "        super().__init__(agent_name, env, reward_threshold, max_steps)\n",
    "\n",
    "    def step(self, action=None):\n",
    "        obs, reward, done, info = self.env.step(action=action)\n",
    "        self.step_counter += 1\n",
    "        if self.max_steps is not None and self.step_counter >= self.max_steps:\n",
    "            done = True\n",
    "        return np.float32(obs), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_counter = 0\n",
    "        obs = self.env.reset()\n",
    "        return np.float32(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db87200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator_CC1(env_config: dict):\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-7] + f'/Simulator/Scenarios/scenario_files/Scenario1b.yaml'\n",
    "    sg = FileReaderScenarioGenerator(path)\n",
    "    agents = {\"Red\": B_lineAgent(), \"Green\": GreenAgent()}\n",
    "    cyborg = CybORG(scenario_generator=sg, environment='sim', agents=agents)\n",
    "    env = RLLibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e51f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator_CC2(env_config: dict):\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-7] + f'/Simulator/Scenarios/scenario_files/Scenario2.yaml'\n",
    "    sg = FileReaderScenarioGenerator(path)\n",
    "    agents = {\"Red\": B_lineAgent(), \"Green\": GreenAgent()}\n",
    "    cyborg = CybORG(scenario_generator=sg, environment='sim', agents=agents)\n",
    "    env = RLLibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator_CC3(env_config: dict):\n",
    "    sg = DroneSwarmScenarioGenerator()\n",
    "    cyborg = CybORG(scenario_generator=sg, environment='sim')\n",
    "    env = ParallelPettingZooEnv(PettingZooParallelWrapper(env=cyborg))\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc320dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results_dict):\n",
    "    train_iter = results_dict[\"training_iteration\"]\n",
    "    r_mean = results_dict[\"episode_reward_mean\"]\n",
    "    r_max = results_dict[\"episode_reward_max\"]\n",
    "    r_min = results_dict[\"episode_reward_min\"]\n",
    "    print(f\"{train_iter:4d} \\tr_mean: {r_mean:.1f} \\tr_max: {r_max:.1f} \\tr_min: {r_min: .1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facec295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     register_env(name=\"CC1\", env_creator=env_creator_CC1)\n",
    "#     register_env(name=\"CC2\", env_creator=env_creator_CC2)\n",
    "#     register_env(name=\"CC3\", env_creator=env_creator_CC3)\n",
    "#     config = ppo.DEFAULT_CONFIG.copy()\n",
    "#     for env in ['CC1', 'CC2', 'CC3']:\n",
    "#         agent = ppo.PPOTrainer(config=config, env=env)\n",
    "\n",
    "#         train_steps = 1e2\n",
    "#         total_steps = 0\n",
    "#         while total_steps < train_steps:\n",
    "#             results = agent.train()\n",
    "#             print_results(results)\n",
    "#             total_steps = results[\"timesteps_total\"]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
